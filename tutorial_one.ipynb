{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Models\n",
    "_______\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Large Language Model (LLM) is a type of artificial intelligence algorithm that uses neural networks to analyze and generate human-like text, processing vast amounts of data to learn patterns and relationships within language, enabling applications such as natural language processing, text summarization, and conversational AI.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3\")\n",
    "llm.invoke(\"what is a Large Language Model in one sentence\")\n",
    "# for chunck in llm.stream(\"what is a Large Language Model in one sentence\"): \n",
    "#     print(chunck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Prompts\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' LLMs are AI models trained by feeding them huge amounts of text data and then asking them questions.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "Schema = [\n",
    "    SystemMessage(content=\"explain stuff to me like a 5 years old\"),\n",
    "    HumanMessage(content=\"explain LLMs in one sentence \")\n",
    "]\n",
    "llm.invoke(Schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Prompt Templates\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Your Prompt is : Whats the Capital of Palestine only print the name of it nothing else\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ramallah'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"Whats the Capital of {country} only print the name of it nothing else\"\n",
    ")\n",
    "\n",
    "print(\"==============================\")\n",
    "message = input(\"[Whats the Capital of ]  :  \")\n",
    "user_prompt = capital_prompt.format(country=message)\n",
    "print(f\"Your Prompt is : {user_prompt}\")\n",
    "print(\"==============================\")\n",
    "llm.invoke(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Chains\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Damascus!\\n\\nHere\\'s a fun fact: Did you know that the ancient city of Damascus, Syria is known as \"the City of Jasmine\" due to its long history of jasmine cultivation? In fact, Damascus was once one of the most famous centers for jasmine production in the world! The fragrant flowers were used in perfumes, cosmetics, and even as a symbol of wealth and status.\\n\\nIn the 13th century, the city\\'s jasmine industry thrived under the rule of the Ayyubid dynasty. The city\\'s streets were said to be lined with jasmine sellers, and the fragrance wafted through the air, making it one of the most romantic cities in the world!\\n\\nToday, while the jasmine industry may not be as prominent as it once was, Damascus still celebrates its jasmine heritage during festivals like the Jasmine Festival, which takes place every summer.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain \n",
    "\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt)\n",
    "result = capital_chain.run(\"Syria\")\n",
    "\n",
    "history_prompt = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"tell me a fun fact about {capital} \"\n",
    ")\n",
    "\n",
    "history_chain = LLMChain(llm=llm, prompt=history_prompt)\n",
    "history_chain.run(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nprompt\n  Can't instantiate abstract class BasePromptTemplate with abstract methods format, format_prompt (type=type_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleSequentialChain\n\u001b[0;32m----> 3\u001b[0m capital_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapital_chain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m history_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm,prompt\u001b[38;5;241m=\u001b[39mhistory_chain)\n\u001b[1;32m      6\u001b[0m fun_fact_chain \u001b[38;5;241m=\u001b[39mSimpleSequentialChain(\n\u001b[1;32m      7\u001b[0m     chains\u001b[38;5;241m=\u001b[39m[capital_chain,history_chain],\n\u001b[1;32m      8\u001b[0m     \n\u001b[1;32m      9\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/train/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:183\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     emit_warning()\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/train/lib/python3.8/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LLMChain\nprompt\n  Can't instantiate abstract class BasePromptTemplate with abstract methods format, format_prompt (type=type_error)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_chain)\n",
    "history_chain = LLMChain(llm=llm,prompt=history_chain)\n",
    "\n",
    "fun_fact_chain =SimpleSequentialChain(\n",
    "    chains=[capital_chain,history_chain],\n",
    "    \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "fun_fact_chain.run(country=\"France\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
